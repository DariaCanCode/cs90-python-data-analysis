{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Variable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last lecture we learned about linear regression, which is a simple method to find a correlation between an input (independent) and an output (dependent) variable. This is fine if your data only has a single independent variable, but the vast majority of real life data you might analyze will have numerous independent variables (and maybe even multiple dependent variables).\n",
    "\n",
    "For these situations, simple linear regression is not good enough. We need to use **multi-variable linear regression** (also called multiple linear regression). As the name implies, it is a method that finds a correlation between multiple input variables and one output variable.\n",
    "\n",
    "The formula for single variable linear regression is simply the equation of a line you should all know:\n",
    "**y = w \\* x + b**, where **x** is the input variable, **y** is the output variable, **w** is the weight (commonly known as the slope), and **b** is the bias (commonly known as the y-intercept)\n",
    "\n",
    "The formula for multi-variable linear regression is:\n",
    "**y = w_1 \\* x_1 + w_2 \\* x_2 + w_3 \\* x_3 + ... + w_n \\* x_n + b**\n",
    "Here, **y** is still the output variable, same as before, but now we have *multiple* input variables: **x_1**, **x_2**, and so on all the way to **x_n** (you can literally have as many as you want). Of course, each input variable has its own weight, **w_1**, **w_2**, etc, up to **w_n**. And finally, **b**, the bias, is still the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like we did before, let's generate some fake data by starting with a known equation\n",
    "# we will have 3 independent variables\n",
    "def f(x1, x2, x3):\n",
    "    return 2 * x1 + 3 * x2 + (-1) * x3 + 4\n",
    "\n",
    "# as you can see from this equation, x1 and x2 both postively impact the output, with x2 having the most impact,\n",
    "# while x3 actually negatively impacts output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some random values in range 0-10 for each input variable (rounded to 2 decimals)\n",
    "x1, x2, x3 = np.round(np.random.random((3,100)) * 10, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73, 7.6 , 6.83, 2.48, 6.81, 3.96, 3.83, 8.77, 4.41, 1.35, 4.94,\n",
       "       6.79, 3.27, 0.6 , 5.68, 6.3 , 0.05, 3.21, 3.08, 6.02, 9.74, 9.13,\n",
       "       3.34, 6.39, 0.52, 3.29, 3.17, 7.12, 7.98, 4.4 , 8.93, 8.37, 6.43,\n",
       "       9.81, 0.69, 5.81, 8.88, 2.31, 7.89, 8.54, 2.18, 0.37, 5.65, 9.02,\n",
       "       7.67, 6.31, 8.41, 5.93, 0.52, 1.15, 6.  , 7.39, 2.42, 2.21, 7.22,\n",
       "       7.96, 4.08, 1.54, 3.14, 2.51, 1.31, 3.5 , 7.99, 2.75, 8.76, 5.04,\n",
       "       3.08, 1.78, 7.9 , 5.49, 8.67, 2.25, 8.41, 5.64, 5.37, 7.07, 7.38,\n",
       "       1.16, 7.15, 6.53, 3.62, 2.13, 0.73, 2.56, 3.01, 9.63, 9.48, 8.23,\n",
       "       0.34, 8.34, 7.98, 3.46, 3.49, 3.57, 2.79, 1.46, 7.67, 8.98, 9.65,\n",
       "       4.56])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at one of the arrays to see what we've got:\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.08, 33.12, 27.18,  3.25, 38.43, 16.38, 17.12, 23.7 , 17.53,\n",
       "        4.89, 34.55, 40.35, 17.6 ,  0.33,  7.29, 28.64,  5.11, 35.2 ,\n",
       "       26.65, 34.5 , 28.63, 29.16, 22.46, 43.23, 26.25, 23.62, 30.45,\n",
       "       27.9 , 33.21, 25.05, 34.68, 40.96, 31.83, 35.77,  3.69, 37.16,\n",
       "       41.16,  7.82, 40.32, 21.68, 29.6 , 24.96, 28.85, 33.07, 37.7 ,\n",
       "       20.9 , 28.9 , 36.  , 22.49, 16.  , 28.76, 35.66,  9.69, 20.13,\n",
       "       20.62, 31.91, 33.16,  6.95, 25.27,  8.27,  4.3 ,  5.6 , 21.  ,\n",
       "       24.53, 43.92, 34.55, 14.81, 13.62, 30.35, 20.08, 12.01, 15.78,\n",
       "       34.44, 43.41, 10.1 , 17.69, 27.77, 10.69, 34.7 , 34.39, 18.22,\n",
       "       13.69, 11.74, 14.37,  6.21, 41.49, 23.15, 21.25, 25.71, 26.95,\n",
       "       41.53, 22.89, 18.16, 27.16, 35.23, 19.72, 14.24, 23.37, 43.38,\n",
       "       11.74])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create the output values.\n",
    "# Note that these are 'perfect' outputs, without any error or residual at all\n",
    "y = f(x1, x2, x3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now comes the important question:\n",
    "# Given the 3 input arrays and 1 output array,\n",
    "# how do we find the original equation?\n",
    "\n",
    "# The answer is: not by hand, that's for damn sure.\n",
    "# Introducing: sklearn, (full name: scikit-learn)\n",
    "# This is by far one of the most used machine learning libraries in python\n",
    "# We won't even be scratching the surface of its capabilities,\n",
    "# For our purposes we just need a part of it, the linear_model submodule:\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we make the model, let's put our data in the expected format:\n",
    "# pandas dataframe for the inputs, series for the output\n",
    "inputs = pd.DataFrame({\n",
    "    'x1': x1,\n",
    "    'x2': x2,\n",
    "    'x3': x3\n",
    "})\n",
    "output = pd.Series(y, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we're ready to model.\n",
    "# It's as simple as this:\n",
    "# 1. create a new LinearRegression model\n",
    "lr = linear_model.LinearRegression()\n",
    "# 2. fit the data\n",
    "lr.fit(inputs, output)\n",
    "# 3. Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared:  1.0\n"
     ]
    }
   ],
   "source": [
    "# That's it. the regression model just did all the hard work,\n",
    "# all that's left for you to do is analyze the results:\n",
    "\n",
    "# check the r squared score, using LinearRegression.score():\n",
    "print(\"r-squared: \", lr.score(inputs, output))\n",
    "# of course, we expect a perfect score of 1.0, since this data is 100% linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 2.0\n",
      "x1 3.0\n",
      "x2 -1.0\n"
     ]
    }
   ],
   "source": [
    "# check the coefficients using LinearRegression.coef_:\n",
    "for i,coef in enumerate(lr.coef_):\n",
    "    print(f\"x{i}\", np.round(coef, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9999999999999716\n"
     ]
    }
   ],
   "source": [
    "# again, because this is a perfect linear dataset, the model found the exact coefficents\n",
    "# check if it found the correct y-intercept as well (should be 4):\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty much.\n",
    "\n",
    "# having it predict this kind of 'perfect' data is no fun,\n",
    "# let's toss in some random error in our output values.\n",
    "output += np.random.normal(size=y.shape) # generate a normal distribution of error terms to add to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now do the same modeling steps again\n",
    "# we have to get a new LinearRegression model, because the old one has already been fitted with data\n",
    "lr = linear_model.LinearRegression()\n",
    "# fit the data\n",
    "lr.fit(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937176423000278"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the score\n",
    "lr.score(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.96886701  3.03257995 -1.03013763] 4.086396384840132\n"
     ]
    }
   ],
   "source": [
    "# as you can see, the r squared is still pretty high, but not a perfect 1 anymore\n",
    "# same for the coefficients and intercept: they won't exactly match the originals\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate a new set of random input variables, and test our model to see how well it does\n",
    "# we're lazy so we just copy the same code from before\n",
    "x1, x2, x3 = np.round(np.random.random((3,100)) * 10, decimals=2)\n",
    "inputs = pd.DataFrame({\n",
    "    'x1': x1,\n",
    "    'x2': x2,\n",
    "    'x3': x3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two output arrays:\n",
    "# 1. the actual outputs, calculated directly from the true equation\n",
    "y_actual = f(x1, x2, x3)\n",
    "actual_output = pd.Series(y_actual, name=\"Actual Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Output</th>\n",
       "      <th>Predicted Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.97</td>\n",
       "      <td>41.850558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.09</td>\n",
       "      <td>-3.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.58</td>\n",
       "      <td>19.598420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.95</td>\n",
       "      <td>33.292888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.61</td>\n",
       "      <td>26.494450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.28</td>\n",
       "      <td>40.119621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.85</td>\n",
       "      <td>6.498407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.70</td>\n",
       "      <td>32.799097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.03</td>\n",
       "      <td>35.936376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.02</td>\n",
       "      <td>31.747884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.04</td>\n",
       "      <td>27.838364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.81</td>\n",
       "      <td>15.454881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.07</td>\n",
       "      <td>12.907110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31.20</td>\n",
       "      <td>31.073834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.76</td>\n",
       "      <td>11.794692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37.50</td>\n",
       "      <td>37.509380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.42</td>\n",
       "      <td>28.179522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.36</td>\n",
       "      <td>14.190391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.16</td>\n",
       "      <td>36.108046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.76</td>\n",
       "      <td>29.677679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.37</td>\n",
       "      <td>4.315410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.88</td>\n",
       "      <td>19.819456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47.51</td>\n",
       "      <td>47.533059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.88</td>\n",
       "      <td>15.695233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40.53</td>\n",
       "      <td>40.433985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.04</td>\n",
       "      <td>11.829669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.17</td>\n",
       "      <td>16.037384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.19</td>\n",
       "      <td>12.211438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.54</td>\n",
       "      <td>20.429729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28.19</td>\n",
       "      <td>28.064522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>42.31</td>\n",
       "      <td>42.328258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>32.32</td>\n",
       "      <td>32.527257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>35.67</td>\n",
       "      <td>35.638539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.761584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>46.73</td>\n",
       "      <td>46.800947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>35.83</td>\n",
       "      <td>36.095191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>11.46</td>\n",
       "      <td>11.384425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.57</td>\n",
       "      <td>22.408546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>36.22</td>\n",
       "      <td>36.234183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>31.29</td>\n",
       "      <td>31.397146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>11.62</td>\n",
       "      <td>11.443287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>21.30</td>\n",
       "      <td>21.416506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30.73</td>\n",
       "      <td>30.888971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>32.86</td>\n",
       "      <td>32.915815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16.39</td>\n",
       "      <td>16.137801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>17.11</td>\n",
       "      <td>16.850617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>19.70</td>\n",
       "      <td>19.439974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>32.67</td>\n",
       "      <td>32.759096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15.80</td>\n",
       "      <td>15.666818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>24.68</td>\n",
       "      <td>24.418522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>40.60</td>\n",
       "      <td>40.528964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>21.26</td>\n",
       "      <td>21.368584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>37.28</td>\n",
       "      <td>37.118668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>22.90</td>\n",
       "      <td>22.681186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37.25</td>\n",
       "      <td>37.169810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>38.67</td>\n",
       "      <td>38.760974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>38.43</td>\n",
       "      <td>38.515906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.13</td>\n",
       "      <td>21.220339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30.47</td>\n",
       "      <td>30.294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30.72</td>\n",
       "      <td>30.976784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Output  Predicted Output\n",
       "0           41.97         41.850558\n",
       "1           -3.09         -3.345400\n",
       "2           19.58         19.598420\n",
       "3           32.95         33.292888\n",
       "4           26.61         26.494450\n",
       "5           40.28         40.119621\n",
       "6            6.85          6.498407\n",
       "7           32.70         32.799097\n",
       "8           36.03         35.936376\n",
       "9           32.02         31.747884\n",
       "10          28.04         27.838364\n",
       "11          15.81         15.454881\n",
       "12          13.07         12.907110\n",
       "13          31.20         31.073834\n",
       "14          11.76         11.794692\n",
       "15          37.50         37.509380\n",
       "16          28.42         28.179522\n",
       "17          14.36         14.190391\n",
       "18          36.16         36.108046\n",
       "19          29.76         29.677679\n",
       "20           4.37          4.315410\n",
       "21          19.88         19.819456\n",
       "22          47.51         47.533059\n",
       "23          15.88         15.695233\n",
       "24          40.53         40.433985\n",
       "25          12.04         11.829669\n",
       "26          16.17         16.037384\n",
       "27          12.19         12.211438\n",
       "28          20.54         20.429729\n",
       "29          28.19         28.064522\n",
       "..            ...               ...\n",
       "70          42.31         42.328258\n",
       "71          32.32         32.527257\n",
       "72          35.67         35.638539\n",
       "73           3.00          2.761584\n",
       "74          46.73         46.800947\n",
       "75          35.83         36.095191\n",
       "76          11.46         11.384425\n",
       "77          22.57         22.408546\n",
       "78          36.22         36.234183\n",
       "79          31.29         31.397146\n",
       "80          11.62         11.443287\n",
       "81          21.30         21.416506\n",
       "82          30.73         30.888971\n",
       "83          32.86         32.915815\n",
       "84          16.39         16.137801\n",
       "85          17.11         16.850617\n",
       "86          19.70         19.439974\n",
       "87          32.67         32.759096\n",
       "88          15.80         15.666818\n",
       "89          24.68         24.418522\n",
       "90          40.60         40.528964\n",
       "91          21.26         21.368584\n",
       "92          37.28         37.118668\n",
       "93          22.90         22.681186\n",
       "94          37.25         37.169810\n",
       "95          38.67         38.760974\n",
       "96          38.43         38.515906\n",
       "97          21.13         21.220339\n",
       "98          30.47         30.294933\n",
       "99          30.72         30.976784\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. the predicted outputs we get from our model, using the predict() function\n",
    "y_predicted = lr.predict(inputs)\n",
    "predicted_output = pd.Series(y_predicted, name=\"Predicted Output\")\n",
    "# you can compare them manually side-by-side in a dataframe:\n",
    "compare = pd.concat([actual_output, predicted_output], axis=1)\n",
    "compare = pd.DataFrame({\n",
    "    'Actual Output': actual_output,\n",
    "    'Predicted Output': predicted_output,\n",
    "    'Residual': \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Output</th>\n",
       "      <th>Predicted Output</th>\n",
       "      <th>Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.97</td>\n",
       "      <td>41.850558</td>\n",
       "      <td>-0.119442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.09</td>\n",
       "      <td>-3.345400</td>\n",
       "      <td>-0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.58</td>\n",
       "      <td>19.598420</td>\n",
       "      <td>0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.95</td>\n",
       "      <td>33.292888</td>\n",
       "      <td>0.342888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.61</td>\n",
       "      <td>26.494450</td>\n",
       "      <td>-0.115550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.28</td>\n",
       "      <td>40.119621</td>\n",
       "      <td>-0.160379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.85</td>\n",
       "      <td>6.498407</td>\n",
       "      <td>-0.351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.70</td>\n",
       "      <td>32.799097</td>\n",
       "      <td>0.099097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.03</td>\n",
       "      <td>35.936376</td>\n",
       "      <td>-0.093624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32.02</td>\n",
       "      <td>31.747884</td>\n",
       "      <td>-0.272116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.04</td>\n",
       "      <td>27.838364</td>\n",
       "      <td>-0.201636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.81</td>\n",
       "      <td>15.454881</td>\n",
       "      <td>-0.355119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.07</td>\n",
       "      <td>12.907110</td>\n",
       "      <td>-0.162890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31.20</td>\n",
       "      <td>31.073834</td>\n",
       "      <td>-0.126166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.76</td>\n",
       "      <td>11.794692</td>\n",
       "      <td>0.034692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37.50</td>\n",
       "      <td>37.509380</td>\n",
       "      <td>0.009380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.42</td>\n",
       "      <td>28.179522</td>\n",
       "      <td>-0.240478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.36</td>\n",
       "      <td>14.190391</td>\n",
       "      <td>-0.169609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.16</td>\n",
       "      <td>36.108046</td>\n",
       "      <td>-0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>29.76</td>\n",
       "      <td>29.677679</td>\n",
       "      <td>-0.082321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.37</td>\n",
       "      <td>4.315410</td>\n",
       "      <td>-0.054590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.88</td>\n",
       "      <td>19.819456</td>\n",
       "      <td>-0.060544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47.51</td>\n",
       "      <td>47.533059</td>\n",
       "      <td>0.023059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.88</td>\n",
       "      <td>15.695233</td>\n",
       "      <td>-0.184767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40.53</td>\n",
       "      <td>40.433985</td>\n",
       "      <td>-0.096015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.04</td>\n",
       "      <td>11.829669</td>\n",
       "      <td>-0.210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.17</td>\n",
       "      <td>16.037384</td>\n",
       "      <td>-0.132616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.19</td>\n",
       "      <td>12.211438</td>\n",
       "      <td>0.021438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.54</td>\n",
       "      <td>20.429729</td>\n",
       "      <td>-0.110271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28.19</td>\n",
       "      <td>28.064522</td>\n",
       "      <td>-0.125478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>42.31</td>\n",
       "      <td>42.328258</td>\n",
       "      <td>0.018258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>32.32</td>\n",
       "      <td>32.527257</td>\n",
       "      <td>0.207257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>35.67</td>\n",
       "      <td>35.638539</td>\n",
       "      <td>-0.031461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.00</td>\n",
       "      <td>2.761584</td>\n",
       "      <td>-0.238416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>46.73</td>\n",
       "      <td>46.800947</td>\n",
       "      <td>0.070947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>35.83</td>\n",
       "      <td>36.095191</td>\n",
       "      <td>0.265191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>11.46</td>\n",
       "      <td>11.384425</td>\n",
       "      <td>-0.075575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.57</td>\n",
       "      <td>22.408546</td>\n",
       "      <td>-0.161454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>36.22</td>\n",
       "      <td>36.234183</td>\n",
       "      <td>0.014183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>31.29</td>\n",
       "      <td>31.397146</td>\n",
       "      <td>0.107146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>11.62</td>\n",
       "      <td>11.443287</td>\n",
       "      <td>-0.176713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>21.30</td>\n",
       "      <td>21.416506</td>\n",
       "      <td>0.116506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30.73</td>\n",
       "      <td>30.888971</td>\n",
       "      <td>0.158971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>32.86</td>\n",
       "      <td>32.915815</td>\n",
       "      <td>0.055815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>16.39</td>\n",
       "      <td>16.137801</td>\n",
       "      <td>-0.252199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>17.11</td>\n",
       "      <td>16.850617</td>\n",
       "      <td>-0.259383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>19.70</td>\n",
       "      <td>19.439974</td>\n",
       "      <td>-0.260026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>32.67</td>\n",
       "      <td>32.759096</td>\n",
       "      <td>0.089096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15.80</td>\n",
       "      <td>15.666818</td>\n",
       "      <td>-0.133182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>24.68</td>\n",
       "      <td>24.418522</td>\n",
       "      <td>-0.261478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>40.60</td>\n",
       "      <td>40.528964</td>\n",
       "      <td>-0.071036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>21.26</td>\n",
       "      <td>21.368584</td>\n",
       "      <td>0.108584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>37.28</td>\n",
       "      <td>37.118668</td>\n",
       "      <td>-0.161332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>22.90</td>\n",
       "      <td>22.681186</td>\n",
       "      <td>-0.218814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37.25</td>\n",
       "      <td>37.169810</td>\n",
       "      <td>-0.080190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>38.67</td>\n",
       "      <td>38.760974</td>\n",
       "      <td>0.090974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>38.43</td>\n",
       "      <td>38.515906</td>\n",
       "      <td>0.085906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.13</td>\n",
       "      <td>21.220339</td>\n",
       "      <td>0.090339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30.47</td>\n",
       "      <td>30.294933</td>\n",
       "      <td>-0.175067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30.72</td>\n",
       "      <td>30.976784</td>\n",
       "      <td>0.256784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Output  Predicted Output  Residual\n",
       "0           41.97         41.850558 -0.119442\n",
       "1           -3.09         -3.345400 -0.255400\n",
       "2           19.58         19.598420  0.018420\n",
       "3           32.95         33.292888  0.342888\n",
       "4           26.61         26.494450 -0.115550\n",
       "5           40.28         40.119621 -0.160379\n",
       "6            6.85          6.498407 -0.351593\n",
       "7           32.70         32.799097  0.099097\n",
       "8           36.03         35.936376 -0.093624\n",
       "9           32.02         31.747884 -0.272116\n",
       "10          28.04         27.838364 -0.201636\n",
       "11          15.81         15.454881 -0.355119\n",
       "12          13.07         12.907110 -0.162890\n",
       "13          31.20         31.073834 -0.126166\n",
       "14          11.76         11.794692  0.034692\n",
       "15          37.50         37.509380  0.009380\n",
       "16          28.42         28.179522 -0.240478\n",
       "17          14.36         14.190391 -0.169609\n",
       "18          36.16         36.108046 -0.051954\n",
       "19          29.76         29.677679 -0.082321\n",
       "20           4.37          4.315410 -0.054590\n",
       "21          19.88         19.819456 -0.060544\n",
       "22          47.51         47.533059  0.023059\n",
       "23          15.88         15.695233 -0.184767\n",
       "24          40.53         40.433985 -0.096015\n",
       "25          12.04         11.829669 -0.210331\n",
       "26          16.17         16.037384 -0.132616\n",
       "27          12.19         12.211438  0.021438\n",
       "28          20.54         20.429729 -0.110271\n",
       "29          28.19         28.064522 -0.125478\n",
       "..            ...               ...       ...\n",
       "70          42.31         42.328258  0.018258\n",
       "71          32.32         32.527257  0.207257\n",
       "72          35.67         35.638539 -0.031461\n",
       "73           3.00          2.761584 -0.238416\n",
       "74          46.73         46.800947  0.070947\n",
       "75          35.83         36.095191  0.265191\n",
       "76          11.46         11.384425 -0.075575\n",
       "77          22.57         22.408546 -0.161454\n",
       "78          36.22         36.234183  0.014183\n",
       "79          31.29         31.397146  0.107146\n",
       "80          11.62         11.443287 -0.176713\n",
       "81          21.30         21.416506  0.116506\n",
       "82          30.73         30.888971  0.158971\n",
       "83          32.86         32.915815  0.055815\n",
       "84          16.39         16.137801 -0.252199\n",
       "85          17.11         16.850617 -0.259383\n",
       "86          19.70         19.439974 -0.260026\n",
       "87          32.67         32.759096  0.089096\n",
       "88          15.80         15.666818 -0.133182\n",
       "89          24.68         24.418522 -0.261478\n",
       "90          40.60         40.528964 -0.071036\n",
       "91          21.26         21.368584  0.108584\n",
       "92          37.28         37.118668 -0.161332\n",
       "93          22.90         22.681186 -0.218814\n",
       "94          37.25         37.169810 -0.080190\n",
       "95          38.67         38.760974  0.090974\n",
       "96          38.43         38.515906  0.085906\n",
       "97          21.13         21.220339  0.090339\n",
       "98          30.47         30.294933 -0.175067\n",
       "99          30.72         30.976784  0.256784\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's a bit easier to compare if we add a column for the residuals\n",
    "compare['Residual'] = compare['Predicted Output'] - compare['Actual Output']\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7393496599707725"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of course, as we've learned, we can compute our own r-squared score to see how the model did\n",
    "# compute residual sum of squares (rss)\n",
    "rss = np.sum(compare['Residual'].values ** 2)\n",
    "rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13002.003211"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute total sum of squares\n",
    "tss = np.sum((y_actual - np.mean(y_actual)) ** 2)\n",
    "tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999789313260771"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared = 1 - rss / tss\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999789313260771"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A very high r_squared value, as we expected since there wasn't much error in the data.\n",
    "# Of course, instead of computing this ourselves,\n",
    "# we can let the LinearRegression.score() method do it for us:\n",
    "lr.score(inputs, actual_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's pretty much it. That's how simple it is to create a multiple linear regression model, and test its effectiveness.\n",
    "\n",
    "Here, we used fake data, but the idea behind using it on real data is exactly the same: you have a bunch of numerical input variables and a single numerical output variable, and you use the LinearRegression model to fit the data and generate predictions.\n",
    "\n",
    "Notice the repetition of the word *numerical* above. Linear regression ONLY works on numerical data, which is why I emphasized the feature engineering step so much. If your dataset contains categorical data, you have to convert them into numerical data, either using direct integer encoding for ordinal data or one hot encoding for unordered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
